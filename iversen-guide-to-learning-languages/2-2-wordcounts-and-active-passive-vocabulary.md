---
layout: page
title: 2.2 Wordcounts and active/passive vocabulary
author: Iversen
---
In 2009 and again in 2014 I did some research based on my [own](http://how-to-learn-any-language.com/forum/forum_posts.asp?TID=12983&TPN=1) "Multiconfused log" at HTLAL, which grew to monstrous proportions from I started it in 2008 until I stopped adding to it in October 2015 - all in all close to 4000 messages in a number of languages, but first and foremost in English. The numbers below only refer to English passages wriitten by me, excluding quotes from other HTLAL messages:

![Wordforms vs occurrence frequencies in Iversen's messages from 2009 and 2014.](../2-2-image-1.jpg)

As you can see, I collected one corpus of roughly 15000 English words in 2009 and two corpora in 2014, each with around 36000 words (or rather word forms). Wordforms are shown along the x axis. In both rounds I reduced the original corpora to unique wordforms in a spreadsheet, and these I reduced manually to headwords and got the results you see above along the y axis (there are more details about the methods in a [message](http://%20http://how-to-learn-any-language.com%20/forum/forum_posts.asp?TID=12983&TPN=451) in my HTLAL log from May 10, 2014).

When I made my first analysis in 2009 it seemed that the conclusion was that you could survive on a fairly small core vocabulary - after all I had written about a bewildering lot of themes in the three months period covered by the sample. But looking at the diagram above it seems that the size of the vocabulary used is growing as a linear function of the sample size. At some point there must be some kind of saturation point where the curve starts to level out, but we are not near that with just 6000 unique headwords. However the most interesting thing is that each of the two corpora from  2014 only shares roughly half its words with the other sample. Or in other words: roughly a third of all the words are common to the two samples, and two thirds of the words are found in just one of the samples. Among the 2000 or so common words you will definitely find the high frequency words of English, which include the 'grammar words' and - given the context- words that have something to do with language learning. But there will definitely also be some words which I use often, but other authors only would use once in a blue moon. 

If you look back at the cumulative curve in the preceding chapter, you will see that the 98% coverage recommended by Hu and Nation corresponds to almost 7000 wordforms (more precisely: 6718 wordforms according to my statistics). It is anyone's guess how much that would be in word families, but  given that English substantives have singular and plural (and a genitive), and that most verbs have three finite forms and some infinite ones, the number of  word families in the Kilgariff sample of some 10 mio. words might hover around 3-4.000 word families or 5-6.000 headwords - just my guess, but with some justification in the results I got during my vocabulary analysis in 2014.  Paul Nation quotes some estimates of the vocabulary needed for "unassisted comprehension of written and spoken English"  in his article "How [Large](http://www.victoria.ac.nz/lals/about/staff/publications/paul-nation/2006-How-large-a-vocab.pdf) a Vocabulary Is Needed For Reading and Listening?":

![Word coverage in selected English novels and newspapers.](../2-2-image-2.jpg)

But as my own results with data from my log showed, the overlap between the vocabulary in one book or magazine and another, even by the same author, may be fairly low. This means that you can't just read the tables above and conclude that 9000 words is enough to read all English novels - you'll definitely need more words to do that. And that may come as a shock to learners that the numbers are so high. Luckily there are some caveats. First: do you really need to know each and every word in a book to enjoy it? Every plant, every flower, every part of a medieval fortress? Probably not, and if you see an unknown word you can try to look it up. No need to panic. Secondly: these numbers all refer to passive vocabulary, but even native speakers won't be able to remember all their words at the turn of a hat. In many cases it is enough that you can recognize the words when you see them.

I doubt that there is any scientifically sound method to evaluate the size of a person's active vocabulary, but my own unscientific gut feeling is that I could see myself using most of the words I know in Danish and a fair share of those I know in English - heaven knows how much, but let's just say two thirds. And from there it goes downwards to the languages which I can read, but hardly speak because I haven't spent enough time and effort on using them actively. An added difficulty is that the context in which you are expected to produce a certain word has a lot to say about how difficult or easy it is. For instance I remember a lot more words in Spanish when I'm in the country and hear the language around me all the time than I do at home, where I don't think or speak or write in Spanish all the time. This effect hits the active skills - including your ability to  produce suitable words in a concrete context - much harder than it hits the passive skills like reading and listening. 

So I can't give reliable figures for the size of my active  vocabulary, but I have made a lot of assessments concerning my passive vocabulary in different languages, and  I do these word counts using a dictionary. There are alternatives for some languages on the internet, where your vocabulary size is measured using methods that build on the assumption that people with large vocabularies know a lot of extremely rare and learned words. But if you have learnt a bit of Latin this may lead to exaggerated results. With badly constructed tests you may even get higher scores by making more or less wild guesses, but the better ones incorporate non-existing words to catch such attempts to cheat the system. The Testyourvocab.com homepage has not only got an online test, but also a blog with some relevant hints both as to the results as to the methodology behind the test. Some of their results look as follows:

* *Most adult native test-takers range from 20,000â€“35,000 words*
* *Average native test-takers of age 8 already know 10,000 words*
* *Average native test-takers of age 4 already know 5,000 words*
* *Adult native test-takers learn almost 1 new word a day until middle age*
* *Adult test-taker vocabulary growth basically stops at middle age*

* *The most common vocabulary size for foreign test-takers is 4,500 words*
* *Foreign test-takers tend to reach over 10,000 words by living abroad*
* *Foreign test-takers learn 2.5 new words a day while living in an English-speaking country*

The most shocking figure here is the extremely low score for foreign test takers living at home - 4500 words is a dismal score by any standard. And it is even more shocking when you consider that people who spend time taking vocabulary tests on the internet supposedly are more interested in languages than your average Joe. A complete distribution curve for foreign learners can be seen at the [testyourvocab](http://testyourvocab.com/blog/2011-07-25-New-results-for-foreign-learners#mainchartNonnative) site:

![Non-native English speaker distribution by vocabulary level. It heavily skews towards the lower end of the scale between 3000 and 6500 words, peaking at 4500. The vocabulary scale goes up to 30000 words, where some respondents are still found.](../2-2-image-3.jpg)

Here it strikes you that the distribution isn't bellshaped - most learners end up at the bottom of the scale, but the curve also shows that the sky is the limits for the 'good' learners - whatever that is. 

The same source also have some extremely interesting information about the role of reading fiction, cfr. the graphic below. Other sources suggest that reading quality non-fiction texts is less efficient, but my own gut feeling is that the language in science mags isn't too different from the one you find in ordinary mainstream novels. It would however be relevant to see whether reading books on paper generally gives more than reading messages and blogs on the internet, but unfortunately I haven't seen any direct comparisons between users of these two communication channels. 
 
![Average ENglish native speaker vocabulary by age and reading habits. Those who read "lots" and in particularly "lots" of fiction score highest across all ages.](../2-2-image-4.jpg)

I have done a number of online tests, mostly for English. With Testyourvocab I got 40.900 words, while another test put 51.000 words on my scoreboard, and the test at [Plenilune](http://www.plenilune.pwp.blueyonder.co.uk/vocabulary.asp) resulted in estimates of 77717 known, 16973 inferred and 8933 familiar words. However my own dictionary based estimates have so far ended up somewhere between 30.000 and 40.000 words, and that's according to a measuring technique which I can apply to other languages. 

The method used with dictionaries is based on choosing random pages in a dictionary and dividing all the headwords on each page into known, unknown and 'dubious', marked by three colours (like blue for OK, green for the middle group and red for the unknown or wrongly translated words. In my earliest tests I didn't have this middle category, but it is nice to have a place to put words which you think you just guessed correctly, or which you definitely could translate if need be, but which deviate in some way from what you would have expected - for instance in the spelling or by having another end vowel. When you have done this for a suitable number of pages, you can divide the figures by the number of pages you have used and multiply by the total number of pages in the dictionary. And by adding the three categories you can also estimate the total number of words in the dictionary, which is necessary for calculating percentages.

Now you will of course be aware that the translations in the dictionary are visible while you look at the headwords, but I have tested the damage done by this by taking the papers with all the words in the three colors I mentioned. If I couldn't give a translation for all the 'known' words on the paper I would have cheated myself. But in practice it seems that the identifications are reasonably trustworthy. I may have problems with a few words, but this is compensated by the fact that I now know some of the previously unknown words. This isn't rock hard science, but it functions.

Another problem: you can obviously not compare a wordcount from a mini dictionary with 5.000 words with one made on a monster with 100.000 words. But I have done so many tests now that I can say with some confidence that the percentages of known and unknown words don't depend much on the size of the dictionary - except with extremely large dictionaries, which are full of rare and arcane and maybe even dialectal words which you don't have to care about. Let's take an example - my Spanish word counts:

![Iversen's Spanish vocabulary measured against selected dictionaries in 2009, 2013 and 2014.](../2-2-image-5.jpg)

As you can see my estimated passive vocabulary fluctuates between 17000 and 34400 , where the highest number by far came by using the monster dictionary of Bratli. The percentages fluctuate far less, but you can see that even the 17% with Bratli results in a higher score than the counts based on midsized dictionaries. With even smaller dictionaries it is evident that you can't get high absolute scores, but the percentages still yield some relevant information. And as an added bonus you can see how much influence it has to land on some pages rather than others just by looking at the estimated total number of words for a given dictionary. So ideally you should count not 5 or 10 pages but maybe a 100 pages to get a reliable results, but it would take forever, and besides there are other, mostly subjective factors which can push the scores up or down - like being in a hurry or having spent a lot of time on the language in question lately. 

So what fun is it to make estimates of your vocabulary size in different languages -  except that I like to count things? Well, to be totally honest: this kind of activity is something few learners would like to spend their precious time on, and there is absolutely no reason they should. If your vocabulary is too restricted you will feel it every time you try to read a book - and that's all you need to know. Maybe I just did it to satisfy a deeply buried remnant of my scientific mind.



Next section: [2.3 Learning words from context](../2-3-learning-words-from-context/)  
Go to [content index](../)
