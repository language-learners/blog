---
layout: page
title: 3.1 Grammar in general - Morphology, Syntax and Chaos
author: Iversen
---
*This section begins the Third part - How to learn grammar.*

When it comes to learning grammar you should consider two cases: the easily specifiable morphology and the more elusive syntax (and the even more elusive idiomatics). 

To learn morphology I make simplified tables according to my own ideas. When I have made up my mind about how some part of the morphological system functions I often write my own version down on thick green paper so that it doesn't get lost among all the white paper sheets I produce every day. While I'm still learning the morphology of a language I try to keep these green sheets within sight so that I can quickly can check an obscure ending when I need to, - that's as least as efficient memorywise as repeating conjugations and declensions all day long. But of course I have to study the tables in the books thoroughly in order to write my green sheets, and that is also part of the learning process. When I write "simplified" I take it to mean that I cut out everything is based on a few words. Exceptions should be learnt as exceptions, they shouldn't clutter your 'general case' tables. I normally don't use example words, but just indicate the infixes and the endings, plus maybe an indication of forms with likely vowel changes etc. (the exact formulations have to be decided for each language). The reason is that the sheets are to be used in situations where you have a concrete example in mind, not for rote memorization.

Syntax should generally be learnt in close conjunction with actual reading and listening, but some things can also be written down on green sheets - like for instance the cases used with certain prepositions or the main situations where you have to choose a perfective verb in a Slavic languaghe. 

To get a hold on some specific grammatical topic area the most efficient way is to see (and think about) a lot of examples in real life. Unfortunately even the thickest grammars generally lack the requisite avalance of examples of a particular phenomenon which could hammar it into your head. For space reasons most grammars just have one or two examples of each phenomenon, and monographies have a tendency to concentrate on rare and maybe theoretically significant constructions rather the common ones. Some language learning systems try to fill the void with drills (FSI - I'm looking at you!), but you have to be a masochist to find such systems amusing. Language guides typically try to vary their sentences, and they do so to such an extent that you can't see any system behind their sample sentences. One of the better in this respect is the small book called "Conversational English - Cebuano" - cfr. the example below, but it would be even better if each example had a hyperliteral transltion and an explanation. 

My point is that it would be nice to have some wellstructured collections that illustrated a few very common constructions - with the cases you actually will see over and over. 

![Short sample from Conversational Cebuano, showing the Cebuano equivalents of a few common English phrases.](../3-1-image-1.jpg)

One way to use a grammar is to read about one topic and then try yo look for examples - and maybe even make a collection. It definitely won't cover all the constructions you will see in your grammar book, but the important thing is to teach yourself to be more vigilant so that you actually notice the relevant things you are confronted with in real life. In other words: one of the main lessons you should get from studying grammar books is the system of categories you need to analysize concrete examples. Another important thing is to avoid being focused entirely on the 'macro meaning'. If your goal is to learn to produce relative clauses then it is irrelevant whether the heroine in your book gets eaten alive by giant zombie maggots or married to the hero. Only the semantic structure of the sentence is relevant.

The most influential grammar school among professional linguists in the world right now seems to be some kind of trasnsformational grammar. This kind of linguistics popped up like a bombshell from outer space in 1957 with Noam Chomsky's book "Syntactic Structures", where he compared three main types of grammars: finite state grammars (roughly grammars that see utterances as structures constructed in a linear fashion),  phrase structure grammars (i.e. models based on immediate constituent analysis) and his own proposal, the transformational generative grammar, which since 1957 has been revised again and again. But basically he expected to reach a point with this last kind of grammar, where it could produce all grammatical sentences and none of the ungrammatical ones (as judged by a native speaker). And this claim to generality is the thing that bothers me most. My own gut feeling tells me to start with something that has meaning (basically words, but affixes and certain combinations of words also qualify). The entities have certain construction possibilities, and on that basis I want to construct all the sentences in the universe. This is in fact how an old-fashioned grammar functions.

It is often stated that Chomsky proved that neither finite state grammars nor phrase structure grammars could  deliver similar complete descriptions of a language. That's correct, but also somewhat misleading. He delivered some rather convincing evidence that a 'left-to-right' grammar would run into problems, but his arguments against phrase structure grammars were mostly based on the fact that they had to be very complicated to explain all complicated sentences, and they couldn't explain the differences in meaning between sentences with superficially identical structures. And he remedied this by adding a transformational layer. However after close to forty years it has to be said that transformational grammar(s) have failed to deliver. As far as I know NO complete transformational grammar of any language has ever been published (please tell me if you have seen one), whereas there are traditional grammars from the preceding generations which come close to be all-encompassing descriptions of their targets - like for instance Maurice Grevisse's "Le Bon Usage".

My own explanation for this is this sad state of affairs is that Chomsky was right in introducing a transformational layer, but he put it on top of the constituent structure grammar he just had dismissed as insufficient. The main difference between such a grammar and a valency (or dependency) grammar of some kind is that you postulate a structure and then fill out the holes with concrete words, which you afterwards put in a certain morphological form. In a valency grammar you have words with some construction potentials, and you build sentences by combining the possibilities of the concrete words. Because the words are there from the beginning you don't have to ask yourself where the semantics come from, and the semantics are still there while you have made your transformations. This is illustrated in a very pedagogical way in Wikipedia (although the analysis as "with a gun" as part of the syntagm built around "man" is dubious):

![Syntax trees from Wikipedia diagraming the sentence "They killed the man with a gun" using both generative grammar and dependency grammar.](../3-1-image-2.jpg)

On of the dubious elements Chomsky took over from the constituent structure grammars is the tendency to see binary structures everywhere, which includes the dubious NP +  VP dichotomy. In contrast valency grammars generally see the finite verb as the one that organizes the main structure of the sentence -  and that includes the subjects, different kinds of objects and adverbials.  If there isn't a finite verb then the uppermost level must of course another kind of word, for instance a substantive, or it could be an interjection. And sometimes the finite verb is a dummy or even missing, even though the structure of the rest of the sentence suggests that there should have been one. For instance you will typically omit the copula verb in the present in Russian (a 'copula verb' is something like 'to be' in English), but include it in the past tense - and apart from some complications around the case of the subject predicative the sentence structures are the same with and without a visible verb. But this is not the main argument - the point is that at last in the Indoeuropean languages the structure of the sentence is dictated by the verbal and not by one of the nominal clauses in it. And the choice of verb dictates the possible layouts of the sentence.

You might have expected a postulated grammar machine à la Chomsky to be ideal for constructing  machine translation systems, but ironically the most successful system among these, Goggle Translate, has not a shred of transformational grammar in it. And no commercial language teaching system has ever been based entirely on transformational grammar

My own stance on this is that the structure of simple sentences hasn't ever been described more efficiently AND pedagogically than with valency grammars, supplemented with elements from field structure grammars where applicable, while transformational descriptions are indispensable if you which to describe and explain more complicated structures. And I have a gut feeling that this is the way language actually works: our language production mechanism is based on concrete words and affixes with built-in semantic and grammatical properties which may suffice to form the simplest structures - but then we use transformations to complicate things. 

For me  sentences are organized like Chinese boxes (or Russian матрёшка dolls), and at each level the central 'organizer' normally is a verb, - at least in the Indoeuropean languages. Attached to this verb are some fields, which can be filled out with single words or organized structures, generically known as syntagmas (syntagmata in correct Greek), and the most important type of syntagma is the nominal syntagma which has a noun as its core and articles, adjectives and some other kinds of words around it. 

A sentence is a box with concrete words or boxes at different levels, and words are connected by rods which sometimes point out of a box. One kind of rod connects a verb and (for instance) a direct object, another kind connects pronouns with their 'antecedents', i.e. the things they points to (with interrogative pronouns this is expected to occur in the answer). But the structures can also be seen as linear constructs, and the rules that govern word order may refer to grammatical functions, although these don't suffice to dictate every aspect of word order. 

For instance conjunctions have a tendency to stand first in a sentence, and by occupying this position they tend to push other elements to later positions -  as evidenced by the word order in subordinate clauses in German:

"Der mann ist hier" ---> "Ich habe gesehen, daß der man hier ist"  
(the man is here ---> *I have seen, that the man here is)

But other languages don't have this rule, and the language learner has to be able to spot and analyze the differences in word order in different languages. That's part of learning a foreign language, and it would be much easier if your grammars and textbooks gave you a simple explanation and supplemented that with a lot of examples that clearly showed the mecanics.

So to deal with a standard grammar  imagine that you should make a short summary of each chapter, where you put the statements into some kind of table or a tree structure. Sort out what you really have to know and what mostly is there to placate the author's collegues. Try comparing the statements of two grammars concerning some specific topic. You may find that they even differ on quite elementary things like morphology. Take an example: in Irish there are simple verbal forms and compound verbal forms, and different grammars and textbook do absolutely not agree on where the dividing line is. Grammars should be taken with a pinch of salt: they are simple tools and shouldn't be regarded as infallible holy books.



Next section: [3.2 Morphology in general](../3-2-morphology-in-general/)  
Go to [content index](../)
